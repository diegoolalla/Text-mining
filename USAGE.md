# Gu√≠a de Uso - Clasificador Binario ProfNER

## Descripci√≥n General

Este proyecto implementa un **clasificador binario** para identificar tweets que mencionan profesiones durante la pandemia de COVID-19, utilizando el corpus ProfNER y modelos de HuggingFace.

## üìã Contenido del Proyecto

### Archivos Principales

1. **profner_classifier.ipynb** - Notebook Jupyter principal con todo el pipeline
2. **predictions.tsv** - Archivo de predicciones en formato TSV
3. **create_deliverable.py** - Script para crear el entregable ZIP
4. **verify_project.py** - Script de verificaci√≥n del proyecto
5. **requirements.txt** - Dependencias del proyecto
6. **README.md** - Documentaci√≥n principal

## üöÄ Instalaci√≥n y Configuraci√≥n

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/diegoolalla/text-mining.git
cd text-mining
```

### Paso 2: Instalar Dependencias

```bash
pip install -r requirements.txt
```

#### Dependencias Principales:
- `transformers` - Modelos de HuggingFace
- `datasets` - Carga y manejo de datasets
- `torch` - PyTorch para deep learning
- `scikit-learn` - M√©tricas y evaluaci√≥n
- `pandas` - Manipulaci√≥n de datos
- `matplotlib` y `seaborn` - Visualizaciones
- `wordcloud` - Nubes de palabras

### Paso 3: Verificar la Instalaci√≥n

```bash
python verify_project.py
```

## üìä Ejecuci√≥n del Proyecto

### Opci√≥n 1: Jupyter Notebook (Recomendado)

```bash
jupyter notebook profner_classifier.ipynb
```

Luego, ejecutar todas las celdas en orden:
- Menu ‚Üí Run ‚Üí Run All Cells
- O usar Shift+Enter en cada celda

### Opci√≥n 2: Ejecuci√≥n por L√≠nea de Comandos

```bash
jupyter nbconvert --to notebook --execute profner_classifier.ipynb --inplace
```

### Opci√≥n 3: Google Colab

1. Subir el notebook a Google Colab
2. Ejecutar la primera celda para instalar dependencias
3. Ejecutar todas las celdas secuencialmente

## üéØ Flujo del Proyecto

### 1. An√°lisis Exploratorio de Datos (EDA)

El notebook realiza un an√°lisis completo incluyendo:
- Estad√≠sticas del dataset (tama√±o, distribuci√≥n de clases)
- An√°lisis de longitud de textos
- Visualizaciones de distribuciones
- Nubes de palabras comparativas

**Salidas generadas:**
- `eda_visualizations.png`
- `wordcloud_comparison.png`

### 2. Selecci√≥n del Modelo

**Modelo: BETO (dccuchile/bert-base-spanish-wwm-cased)**

Justificaci√≥n detallada:
- ‚úÖ Especializado en espa√±ol
- ‚úÖ Arquitectura Transformer con atenci√≥n bidireccional
- ‚úÖ Pre-entrenado con Whole Word Masking
- ‚úÖ ~110M par√°metros (balance capacidad/eficiencia)
- ‚úÖ Rendimiento comprobado en NLP espa√±ol

### 3. Entrenamiento del Modelo

Configuraci√≥n por defecto:
- **√âpocas:** 3
- **Batch Size:** 8
- **Learning Rate:** 2e-5
- **Max Length:** 128 tokens

El entrenamiento incluye:
- Tokenizaci√≥n de textos
- Fine-tuning del modelo BETO
- Validaci√≥n por √©poca
- Selecci√≥n del mejor modelo

### 4. Evaluaci√≥n

M√©tricas calculadas:
- **Accuracy** - Precisi√≥n general
- **Precision** - Por clase
- **Recall** - Exhaustividad
- **F1-Score** - Media arm√≥nica

**Salidas generadas:**
- `confusion_matrix.png`
- Reporte de clasificaci√≥n completo

### 5. Predicciones en Test

Genera predicciones con:
- Etiqueta predicha (0 o 1)
- Probabilidades por clase
- Comparaci√≥n con etiquetas reales

**Salida:** `predictions.tsv`

### 6. An√°lisis de Resultados

Visualizaciones finales:
- Distribuci√≥n de probabilidades
- Comparaci√≥n predicciones vs reales

**Salida:** `prediction_analysis.png`

## üìÅ Formato del Archivo de Predicciones

El archivo `predictions.tsv` contiene columnas separadas por tabuladores:

```
text	true_label	predicted_label	probability_class_0	probability_class_1
Los cardi√≥logos...	1	1	0.1234	0.8766
La vacunaci√≥n...	0	0	0.9012	0.0988
```

### Columnas:
- **text**: Texto del tweet
- **true_label**: Etiqueta real (0: Sin profesi√≥n, 1: Con profesi√≥n)
- **predicted_label**: Etiqueta predicha
- **probability_class_0**: P(Sin profesi√≥n)
- **probability_class_1**: P(Con profesi√≥n)

## üì¶ Crear el Entregable

### Generar archivo ZIP con los entregables:

```bash
python create_deliverable.py
```

Esto crea: `profner_binary_classifier_deliverable.zip`

**Contenido del ZIP:**
1. `profner_classifier.ipynb` - Notebook ejecutable
2. `predictions.tsv` - Archivo de predicciones

## üîç Verificaci√≥n del Proyecto

Para verificar que todo est√° correcto:

```bash
python verify_project.py
```

Este script verifica:
- ‚úÖ Presencia de archivos requeridos
- ‚úÖ Estructura del notebook
- ‚úÖ Archivos opcionales generados

## üìà Resultados Esperados

### Estructura de Archivos Final:

```
text-mining/
‚îú‚îÄ‚îÄ profner_classifier.ipynb          # Notebook principal
‚îú‚îÄ‚îÄ predictions.tsv                    # Predicciones en TSV
‚îú‚îÄ‚îÄ create_deliverable.py              # Script para ZIP
‚îú‚îÄ‚îÄ verify_project.py                  # Verificaci√≥n
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencias
‚îú‚îÄ‚îÄ README.md                          # Documentaci√≥n
‚îú‚îÄ‚îÄ USAGE.md                           # Esta gu√≠a
‚îú‚îÄ‚îÄ .gitignore                         # Archivos ignorados
‚îú‚îÄ‚îÄ eda_visualizations.png             # Generado
‚îú‚îÄ‚îÄ wordcloud_comparison.png           # Generado
‚îú‚îÄ‚îÄ confusion_matrix.png               # Generado
‚îú‚îÄ‚îÄ prediction_analysis.png            # Generado
‚îî‚îÄ‚îÄ profner_binary_classifier_deliverable.zip  # Entregable
```

## üõ†Ô∏è Troubleshooting

### Error: M√≥dulo no encontrado

```bash
pip install -r requirements.txt --upgrade
```

### Error: CUDA no disponible

El c√≥digo funciona en CPU autom√°ticamente. Para usar GPU:
- Instalar PyTorch con soporte CUDA
- Verificar drivers NVIDIA

### Error: Memoria insuficiente

Reducir batch size en el notebook:
```python
BATCH_SIZE = 4  # o menor
```

### Notebook no se ejecuta completamente

Ejecutar celdas una por una para identificar errores espec√≠ficos.

## üìä Personalizaci√≥n

### Cambiar el Modelo

En el notebook, modificar:
```python
MODEL_NAME = "otro-modelo-espa√±ol"
```

Opciones alternativas:
- `"PlanTL-GOB-ES/roberta-base-bne"`
- `"bertin-project/bertin-roberta-base-spanish"`
- `"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es"`

### Ajustar Hiperpar√°metros

```python
EPOCHS = 5              # M√°s √©pocas
BATCH_SIZE = 16         # Mayor batch
LEARNING_RATE = 3e-5    # Diferente LR
MAX_LENGTH = 256        # Secuencias m√°s largas
```

## üìù Notas Importantes

1. **Dataset**: El notebook incluye l√≥gica para cargar el dataset ProfNER desde HuggingFace o crear uno sint√©tico para demostraci√≥n.

2. **Reproducibilidad**: Se establece semilla aleatoria (seed=42) para resultados reproducibles.

3. **Guardado de Modelo**: El notebook incluye opci√≥n para guardar el modelo entrenado en `./profner_model/`.

4. **Tiempo de Ejecuci√≥n**: 
   - CPU: ~10-15 minutos
   - GPU: ~2-5 minutos

## üîó Referencias

- **ProfNER Dataset**: Corpus de tweets COVID-19 con anotaciones de profesiones
- **BETO**: BERT en espa√±ol con Whole Word Masking
- **HuggingFace Transformers**: https://huggingface.co/transformers/

## üìß Soporte

Para preguntas o problemas:
1. Revisar esta gu√≠a
2. Ejecutar `verify_project.py`
3. Verificar logs del notebook
4. Revisar issues en el repositorio

## ‚úÖ Checklist de Entrega

- [ ] Ejecutar el notebook completo
- [ ] Verificar que se gener√≥ `predictions.tsv`
- [ ] Revisar las visualizaciones generadas
- [ ] Ejecutar `verify_project.py`
- [ ] Crear el ZIP con `create_deliverable.py`
- [ ] Verificar contenido del ZIP

---

**Proyecto de Text Mining - Clasificador Binario ProfNER**
**√öltima actualizaci√≥n:** Enero 2026
