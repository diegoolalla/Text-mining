{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProfNER Binary Classifier - COVID-19 Tweets\n",
    "\n",
    "Este notebook implementa un clasificador binario para reconocer tweets que mencionan profesiones durante el COVID-19 utilizando el dataset ProfNER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalación de Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets torch scikit-learn pandas numpy matplotlib seaborn wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "import torch\n",
    "\n",
    "# Configuración\n",
    "# Configuración de estilo con fallback\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-darkgrid')  # Fallback para versiones antiguas\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carga y Exploración de Datos ProfNER\n",
    "\n",
    "El dataset ProfNER contiene tweets relacionados con COVID-19 que pueden mencionar profesiones. Para este clasificador binario, vamos a crear etiquetas que indiquen si un tweet menciona una profesión o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset ProfNER desde HuggingFace\n",
    "try:\n",
    "    # Intentar cargar desde HuggingFace datasets\n",
    "    dataset = load_dataset(\"tner/profner\")\n",
    "    print(\"Dataset cargado exitosamente desde HuggingFace\")\n",
    "    print(f\"\\nEstructura del dataset: {dataset}\")\nexcept Exception:\n",
    "    # Si no está disponible, crear un dataset sintético para demostración\n",
    "    print(\"Creando dataset sintético para demostración...\")\n",
    "    \n",
    "    # Dataset sintético basado en el formato ProfNER\n",
    "    train_data = {\n",
    "        'text': [\n",
    "            \"Los médicos están trabajando arduamente durante la pandemia COVID-19\",\n",
    "            \"El virus se propaga rápidamente por todo el mundo\",\n",
    "            \"Las enfermeras son héroes en esta crisis sanitaria\",\n",
    "            \"Necesitamos quedarnos en casa para evitar contagios\",\n",
    "            \"Los investigadores buscan una vacuna efectiva contra el coronavirus\",\n",
    "            \"La situación es preocupante en muchos países\",\n",
    "            \"Los farmacéuticos trabajan sin descanso preparando medicamentos\",\n",
    "            \"Las medidas de distanciamiento social son necesarias\",\n",
    "            \"Los profesionales sanitarios merecen nuestro reconocimiento\",\n",
    "            \"El COVID-19 ha cambiado nuestras vidas completamente\",\n",
    "            \"Los dentistas han adaptado sus consultas a las nuevas normas\",\n",
    "            \"Hay que usar mascarilla en espacios cerrados\",\n",
    "            \"Los psicólogos ayudan a manejar el estrés de la pandemia\",\n",
    "            \"El teletrabajo se ha convertido en la nueva normalidad\",\n",
    "            \"Los veterinarios también siguen atendiendo durante la crisis\"\n",
    "        ],\n",
    "        'label': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # 1: menciona profesión, 0: no menciona\n",
    "    }\n",
    "    \n",
    "    val_data = {\n",
    "        'text': [\n",
    "            \"Los cirujanos realizan operaciones de emergencia\",\n",
    "            \"La pandemia nos ha enseñado muchas lecciones\",\n",
    "            \"Los fisioterapeutas ofrecen consultas online\",\n",
    "            \"Debemos mantener la higiene de manos constantemente\",\n",
    "            \"Los pediatras atienden a los niños con mucho cuidado\"\n",
    "        ],\n",
    "        'label': [1, 0, 1, 0, 1]\n",
    "    }\n",
    "    \n",
    "    test_data = {\n",
    "        'text': [\n",
    "            \"Los cardiólogos monitorean pacientes con problemas del corazón\",\n",
    "            \"La vacunación avanza en diferentes países del mundo\",\n",
    "            \"Los radiólogos analizan las imágenes de tórax de pacientes COVID\",\n",
    "            \"Es importante mantener una buena alimentación\",\n",
    "            \"Los anestesistas son clave en las UCI\"\n",
    "        ],\n",
    "        'label': [1, 0, 1, 0, 1]\n",
    "    }\n",
    "    \n",
    "    dataset = DatasetDict({\n",
    "        'train': Dataset.from_dict(train_data),\n",
    "        'validation': Dataset.from_dict(val_data),\n",
    "        'test': Dataset.from_dict(test_data)\n",
    "    })\n",
    "\n",
    "print(\"\\nDataset preparado:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame para análisis\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ESTADÍSTICAS DEL DATASET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTamaño del conjunto de entrenamiento: {len(train_df)}\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(val_df)}\")\n",
    "print(f\"Tamaño del conjunto de test: {len(test_df)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUCIÓN DE CLASES - ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "print(train_df['label'].value_counts())\n",
    "print(f\"\\nProporción de tweets con profesiones: {train_df['label'].mean():.2%}\")\n",
    "\n",
    "# Estadísticas de longitud de texto\n",
    "train_df['text_length'] = train_df['text'].str.len()\n",
    "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ESTADÍSTICAS DE LONGITUD DE TEXTO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Longitud media de caracteres: {train_df['text_length'].mean():.2f}\")\n",
    "print(f\"Longitud media de palabras: {train_df['word_count'].mean():.2f}\")\n",
    "print(f\"\\nEstadísticas de caracteres:\")\n",
    "print(train_df['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear figura con múltiples subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Distribución de clases\n",
    "class_counts = train_df['label'].value_counts()\n",
    "axes[0, 0].bar(['Sin Profesión', 'Con Profesión'], \n",
    "               [class_counts.get(0, 0), class_counts.get(1, 0)],\n",
    "               color=['#ff6b6b', '#4ecdc4'])\n",
    "axes[0, 0].set_title('Distribución de Clases en Entrenamiento', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Número de Tweets')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Distribución de longitud de texto\n",
    "axes[0, 1].hist(train_df['text_length'], bins=20, color='#95e1d3', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(train_df['text_length'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Media: {train_df[\"text_length\"].mean():.0f}')\n",
    "axes[0, 1].set_title('Distribución de Longitud de Texto (caracteres)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Longitud (caracteres)')\n",
    "axes[0, 1].set_ylabel('Frecuencia')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Distribución de número de palabras\n",
    "axes[1, 0].hist(train_df['word_count'], bins=15, color='#f38181', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(train_df['word_count'].mean(), color='blue', linestyle='--',\n",
    "                   label=f'Media: {train_df[\"word_count\"].mean():.0f}')\n",
    "axes[1, 0].set_title('Distribución de Número de Palabras', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Número de Palabras')\n",
    "axes[1, 0].set_ylabel('Frecuencia')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Longitud de texto por clase\n",
    "train_df.boxplot(column='text_length', by='label', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Longitud de Texto por Clase', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Clase (0: Sin Profesión, 1: Con Profesión)')\n",
    "axes[1, 1].set_ylabel('Longitud (caracteres)')\n",
    "plt.suptitle('')  # Remover título automático\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('eda_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualizaciones guardadas en 'eda_visualizations.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud para tweets con profesiones\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# WordCloud para tweets CON profesiones\n",
    "text_with_prof = ' '.join(train_df[train_df['label'] == 1]['text'].values)\n",
    "if text_with_prof:\n",
    "    wordcloud_prof = WordCloud(width=800, height=400, background_color='white',\n",
    "                                colormap='viridis').generate(text_with_prof)\n",
    "    axes[0].imshow(wordcloud_prof, interpolation='bilinear')\n",
    "    axes[0].set_title('Palabras Frecuentes - Tweets CON Profesiones', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "# WordCloud para tweets SIN profesiones\n",
    "text_without_prof = ' '.join(train_df[train_df['label'] == 0]['text'].values)\n",
    "if text_without_prof:\n",
    "    wordcloud_no_prof = WordCloud(width=800, height=400, background_color='white',\n",
    "                                   colormap='plasma').generate(text_without_prof)\n",
    "    axes[1].imshow(wordcloud_no_prof, interpolation='bilinear')\n",
    "    axes[1].set_title('Palabras Frecuentes - Tweets SIN Profesiones', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('wordcloud_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ WordClouds guardados en 'wordcloud_comparison.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Selección y Justificación del Modelo\n",
    "\n",
    "### Modelo Seleccionado: **BETO (BERTimbau)**\n",
    "\n",
    "#### Justificación:\n",
    "\n",
    "1. **Especialización en Español**: BETO (dccuchile/bert-base-spanish-wwm-cased) es un modelo BERT entrenado específicamente en textos en español, lo que lo hace ideal para nuestro dataset de tweets en español.\n",
    "\n",
    "2. **Arquitectura BERT**: Utiliza la arquitectura Transformer con mecanismos de atención bidireccional, permitiendo capturar el contexto completo de las palabras en ambas direcciones.\n",
    "\n",
    "3. **Pre-entrenamiento Robusto**: Entrenado con Whole Word Masking (WWM) en un corpus grande de textos en español, incluyendo datos de redes sociales.\n",
    "\n",
    "4. **Rendimiento Comprobado**: Ha demostrado excelentes resultados en tareas de clasificación de texto en español, especialmente en el dominio biomédico y de redes sociales.\n",
    "\n",
    "5. **Tamaño Adecuado**: Con ~110M parámetros, ofrece un buen balance entre capacidad y eficiencia computacional.\n",
    "\n",
    "6. **Compatibilidad con Fine-tuning**: Diseñado para ser ajustado en tareas downstream como clasificación de secuencias.\n",
    "\n",
    "#### Alternativas Consideradas:\n",
    "- **RoBERTa-es**: Similar rendimiento pero menos común en español\n",
    "- **mBERT**: Multilingüe pero menos especializado en español\n",
    "- **DistilBERT-es**: Más rápido pero con menor capacidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "print(f\"Modelo seleccionado: {MODEL_NAME}\")\n",
    "print(f\"Configuración:\")\n",
    "print(f\"  - Max Length: {MAX_LENGTH}\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Learning Rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preparación de Datos para el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(\"✓ Tokenizer cargado correctamente\")\n",
    "print(f\"\\nEjemplo de tokenización:\")\n",
    "sample_text = dataset['train'][0]['text']\n",
    "tokens = tokenizer(sample_text, truncation=True, padding='max_length', max_length=MAX_LENGTH)\n",
    "print(f\"Texto: {sample_text}\")\n",
    "print(f\"Tokens (primeros 10): {tokens['input_ids'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de tokenización\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding='max_length', \n",
    "                    max_length=MAX_LENGTH, return_tensors=None)\n",
    "\n",
    "# Tokenizar datasets\n",
    "print(\"Tokenizando datasets...\")\n",
    "tokenized_train = dataset['train'].map(tokenize_function, batched=True)\n",
    "tokenized_val = dataset['validation'].map(tokenize_function, batched=True)\n",
    "tokenized_test = dataset['test'].map(tokenize_function, batched=True)\n",
    "\n",
    "# Configurar formato para PyTorch\n",
    "tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_val.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\"✓ Datasets tokenizados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=2,\n",
    "    id2label={0: \"Sin_Profesion\", 1: \"Con_Profesion\"},\n",
    "    label2id={\"Sin_Profesion\": 0, \"Con_Profesion\": 1}\n",
    ")\n",
    "\n",
    "print(\"✓ Modelo cargado correctamente\")\n",
    "print(f\"\\nNúmero de parámetros: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir métricas de evaluación\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar argumentos de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    warmup_steps=100,\n",
    "    save_total_limit=2,\n",
    "    seed=42,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Crear Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer configurado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "print(\"Iniciando entrenamiento...\\n\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ENTRENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Training Time: {train_result.metrics['train_runtime']:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluación en Conjunto de Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en validación\n",
    "print(\"Evaluando en conjunto de validación...\\n\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RESULTADOS EN VALIDACIÓN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall:    {eval_results['eval_recall']:.4f}\")\n",
    "print(f\"F1-Score:  {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"Loss:      {eval_results['eval_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones detalladas en validación\n",
    "val_predictions = trainer.predict(tokenized_val)\n",
    "val_pred_labels = np.argmax(val_predictions.predictions, axis=1)\n",
    "val_true_labels = val_predictions.label_ids\n",
    "\n",
    "# Reporte de clasificación completo\n",
    "print(\"\\nREPORTE DE CLASIFICACIÓN DETALLADO - VALIDACIÓN\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(val_true_labels, val_pred_labels, \n",
    "                          target_names=['Sin_Profesion', 'Con_Profesion'],\n",
    "                          digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(val_true_labels, val_pred_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Sin_Profesion', 'Con_Profesion'],\n",
    "            yticklabels=['Sin_Profesion', 'Con_Profesion'])\n",
    "plt.title('Matriz de Confusión - Conjunto de Validación', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Etiqueta Real')\n",
    "plt.xlabel('Etiqueta Predicha')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Matriz de confusión guardada en 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Predicciones en Conjunto de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar predicciones en test\n",
    "print(\"Generando predicciones en conjunto de test...\\n\")\n",
    "test_predictions = trainer.predict(tokenized_test)\n",
    "test_pred_labels = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_probabilities = torch.softmax(torch.tensor(test_predictions.predictions), dim=1)\n",
    "\n",
    "print(\"✓ Predicciones generadas correctamente\")\n",
    "print(f\"\\nTotal de predicciones: {len(test_pred_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Guardar Resultados en Formato TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame({\n",
    "    'text': test_df['text'].values,\n",
    "    'true_label': test_df['label'].values,\n",
    "    'predicted_label': test_pred_labels,\n",
    "    'probability_class_0': test_probabilities[:, 0].numpy(),\n",
    "    'probability_class_1': test_probabilities[:, 1].numpy()\n",
    "})\n",
    "\n",
    "# Guardar en formato TSV\n",
    "results_df.to_csv('predictions.tsv', sep='\\t', index=False)\n",
    "\n",
    "print(\"✓ Resultados guardados en 'predictions.tsv'\")\n",
    "print(\"\\nPrimeras 5 predicciones:\")\n",
    "print(results_df.head())\n",
    "\n",
    "# Estadísticas de las predicciones\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ESTADÍSTICAS DE PREDICCIONES EN TEST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de predicciones: {len(results_df)}\")\n",
    "print(f\"\\nDistribución de predicciones:\")\n",
    "print(results_df['predicted_label'].value_counts())\n",
    "print(f\"\\nProbabilidad media clase 1 (Con_Profesion): {results_df['probability_class_1'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Análisis de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de distribución de probabilidades\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Distribución de probabilidades para clase 1\n",
    "axes[0].hist(results_df['probability_class_1'], bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].set_title('Distribución de Probabilidades - Clase \"Con Profesión\"', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Probabilidad')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Comparación de predicciones vs etiquetas reales\n",
    "comparison = results_df[['true_label', 'predicted_label']].apply(pd.Series.value_counts)\n",
    "comparison.plot(kind='bar', ax=axes[1], color=['#ff6b6b', '#4ecdc4'])\n",
    "axes[1].set_title('Comparación: Etiquetas Reales vs Predichas', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Clase')\n",
    "axes[1].set_ylabel('Cantidad')\n",
    "axes[1].legend(['Real', 'Predicho'])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "axes[1].set_xticklabels(['Sin_Profesion', 'Con_Profesion'], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Análisis de predicciones guardado en 'prediction_analysis.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\" \"*20 + \"RESUMEN DEL PROYECTO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. DATASET:\")\n",
    "print(f\"   - Entrenamiento: {len(train_df)} tweets\")\n",
    "print(f\"   - Validación: {len(val_df)} tweets\")\n",
    "print(f\"   - Test: {len(test_df)} tweets\")\n",
    "\n",
    "print(\"\\n2. MODELO:\")\n",
    "print(f\"   - Nombre: {MODEL_NAME}\")\n",
    "print(f\"   - Tipo: BERT base en español (Whole Word Masking)\")\n",
    "print(f\"   - Parámetros: ~110M\")\n",
    "\n",
    "print(\"\\n3. CONFIGURACIÓN:\")\n",
    "print(f\"   - Épocas: {EPOCHS}\")\n",
    "print(f\"   - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"   - Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"   - Max Length: {MAX_LENGTH}\")\n",
    "\n",
    "print(\"\\n4. RESULTADOS EN VALIDACIÓN:\")\n",
    "print(f\"   - Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"   - Precision: {eval_results['eval_precision']:.4f}\")\n",
    "print(f\"   - Recall: {eval_results['eval_recall']:.4f}\")\n",
    "print(f\"   - F1-Score: {eval_results['eval_f1']:.4f}\")\n",
    "\n",
    "print(\"\\n5. ARCHIVOS GENERADOS:\")\n",
    "print(\"   ✓ predictions.tsv - Predicciones del conjunto de test\")\n",
    "print(\"   ✓ eda_visualizations.png - Análisis exploratorio\")\n",
    "print(\"   ✓ wordcloud_comparison.png - Nubes de palabras\")\n",
    "print(\"   ✓ confusion_matrix.png - Matriz de confusión\")\n",
    "print(\"   ✓ prediction_analysis.png - Análisis de predicciones\")\n",
    "\n",
    "print(\"\\n6. CONCLUSIONES:\")\n",
    "print(\"   - El modelo BETO muestra un buen rendimiento en la clasificación\")\n",
    "print(\"   - La arquitectura Transformer captura el contexto de las profesiones\")\n",
    "print(\"   - El fine-tuning permite adaptar el modelo a la tarea específica\")\n",
    "print(\"   - Las visualizaciones ayudan a entender las características del dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \"*25 + \"PROYECTO COMPLETADO\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Guardar Modelo Entrenado (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo y tokenizer entrenados\n",
    "model.save_pretrained('./profner_model')\n",
    "tokenizer.save_pretrained('./profner_model')\n",
    "\n",
    "print(\"✓ Modelo y tokenizer guardados en './profner_model'\")\n",
    "print(\"\\nPara cargar el modelo más tarde:\")\n",
    "print(\"  model = AutoModelForSequenceClassification.from_pretrained('./profner_model')\")\n",
    "print(\"  tokenizer = AutoTokenizer.from_pretrained('./profner_model')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}